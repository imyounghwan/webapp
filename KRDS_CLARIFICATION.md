# KRDS 평가 체계 명확화

## 🔴 중요한 발견!

### 문제 상황
- 보고서의 "웹 편의성" 점수와 시스템의 KRDS 점수가 다름
- 예: 공정거래위원회
  - **보고서**: 87.9점
  - **시스템**: 30점

### 원인 분석
**보고서와 시스템이 완전히 다른 것을 평가하고 있었습니다!**

#### 보고서 (사람 수동 평가)
- **평가 기준**: 디지털 정부서비스 UI/UX 가이드라인
- **평가 항목**: 312개 중 43개 필수 항목
- **평가 카테고리**:
  1. 아이덴티티 (5개): 공식배너, 헤더, 푸터
  2. 탐색 (5개): 메인메뉴, 브레드크럼, 사이드메뉴
  3. 방문 (1개): 메인화면
  4. 검색 (12개): 검색기능, 검색어입력, 결과확인
  5. 로그인 (7개): 로그인 기능, 정보입력
  6. 신청 (13개): 신청대상, 서비스정보, 신청서작성
- **평가 방법**: 사람이 직접 화면 보고 판단
- **예시 항목**:
  - "공식 배너를 모든 화면의 최상단에 제공하여야 함"
  - "메인메뉴 레이블은 좌측으로 정렬하여야 함"
  - "검색 실행 버튼, 검색어 삭제 버튼을 제공하여야 함"

#### 현재 시스템 (기계 자동 평가)
- **평가 기준**: KWCAG 2.2 웹 접근성 가이드라인
- **평가 항목**: 33개 접근성 항목
- **평가 카테고리**:
  1. 인식의 용이성 (9개): 대체 텍스트, 자막, 표 구조
  2. 운용의 용이성 (15개): 키보드 접근, 포커스, 시간 제한
  3. 이해의 용이성 (7개): 언어 표시, 도움말, 오류 수정
  4. 견고성 (2개): 마크업 유효성, 웹앱 접근성
- **평가 방법**: HTML 구조 자동 분석
- **예시 항목**:
  - "모든 의미있는 이미지에 alt 속성 제공"
  - "키보드만으로 모든 기능 사용 가능"
  - "텍스트와 배경의 명도 대비 4.5:1 이상"

## 📊 점수 차이의 이유

| 구분 | 보고서 (UI/UX 편의성) | 시스템 (웹 접근성) |
|---|---|---|
| **평가 대상** | UI/UX 편의성 | 웹 접근성 |
| **평가 방법** | 사람 수동 평가 | HTML 자동 분석 |
| **평가 항목** | 43개 (UI/UX) | 33개 (접근성) |
| **공정거래위** | 87.9점 | 30점 |

**→ 완전히 다른 것을 측정하므로 점수 비교 불가!**

## ✅ 해결 방안

### 방안 1: 보고서 평가 방식을 시스템에 추가 ⭐ (추천)
- 디지털 정부서비스 UI/UX 가이드라인 43개 항목을 HTML 자동 분석으로 평가
- 보고서와 동일한 카테고리 구조 (아이덴티티, 탐색, 방문, 검색, 로그인, 신청)
- 이것이 **진짜 KRDS 평가**
- 구현 파일: `src/analyzer/uiuxEvaluator.ts` (생성 완료)

### 방안 2: 현재 접근성 평가 유지
- KWCAG 2.2 접근성 평가는 별도로 유지
- 두 가지 평가 모드 제공:
  1. **KRDS (UI/UX 편의성)**: 디지털 정부서비스 가이드라인 43개 항목
  2. **접근성 (KWCAG)**: 웹 접근성 가이드라인 33개 항목

## 🚀 다음 단계

1. ✅ uiuxEvaluator.ts 생성 완료
2. ⏳ API 엔드포인트 수정 (mode=public → UI/UX 평가)
3. ⏳ 프론트엔드 결과 표시 수정
4. ⏳ 43개 항목 평가 로직 정밀화
5. ⏳ 10개 기관 데이터로 검증

## 📝 현재 상태

- **uiuxEvaluator.ts**: ✅ 생성 완료 (43개 항목 기본 로직)
- **API 통합**: ⏳ 대기 중
- **프론트엔드**: ⏳ 대기 중
- **검증**: ⏳ 대기 중

---

**결론**: 보고서의 87.9점과 시스템의 30점은 **완전히 다른 평가 기준**이므로 비교할 수 없습니다. 진짜 KRDS는 UI/UX 편의성 평가이며, 이를 시스템에 추가 중입니다.
